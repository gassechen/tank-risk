import socket
import json
import textwrap
import os
import sys
from google import genai
from google.genai import types

# --- 1. CONFIGURACIN Y CHEQUEOS BSICOS ---

HOST = "127.0.0.1"
PORT = 5001

# Chequeo de clave API y cliente Gemini
if not os.getenv("GEMINI_API_KEY"):
    print("Error: La variable de entorno GEMINI_API_KEY no est谩 configurada.")
    sys.exit(1)

try:
    CLIENT = genai.Client()
except Exception as e:
    print(f"Error al inicializar el cliente Gemini: {e}")
    sys.exit(1)

# ====================================================================
# 2. DEFINICIN DE INSTRUCCIONES ESTTICAS (La Ingenier铆a de Contexto)
# ====================================================================

SYSTEM_INSTRUCTION = textwrap.dedent("""
    Eres un Ingeniero Experto en Integridad Mec谩nica y programador Senior de reglas LISA (LISP). 
    Tu FUNCIN ES CREAR CONOCIMIENTO e INFERIR la 'accion' y la 'norma' faltante.
    
    REGLAS CRTICAS DE SINTAXIS (CUMPLIMIENTO OBLIGATORIO):
    1. La regla debe incluir los par茅ntesis vac铆os '()' inmediatamente despu茅s del nombre. 
    2. El patr贸n de hecho debe ser: (tank-risk (riesgo ?r) (confianza ?c) (espesor ?e)) -- 隆PROHIBIDO USAR ?f <-!
    3. LA SALIDA DE LA REGLA DEBE USAR SLO (format t "...") PARA IMPRIMIR LA SUGERENCIA. PROHIBIDO USAR (assert (recommendation...)).
    4. Para la cl谩usula (test), debes usar operadores de desigualdad (<, >) o (>=, <=) para generalizar las condiciones num茅ricas (confianza y espesor), creando una regla con rango l贸gico.
    5. Usa la funci贸n '(string=)' para comparar cadenas.
    PROHIBIDO: No uses JSON, ni markdown, ni explicaciones, ni texto adicional.
""")

# ====================================================================
# 3. FUNCIN PRINCIPAL DE LLAMADA AL LLM
# ====================================================================

def generate_lisa_rule(data):
    """
    Recibe el contexto completo del fallo (JSON deserializado) y llama a la API de Gemini.
    """
    try:
        if 'eval_input' not in data or 'fallos_output' not in data:
            return {"error": "JSON de entrada incompleto. Faltan 'eval_input' o 'fallos_output'."}

        # Extracci贸n de datos
        EVAL_INPUT = data["eval_input"]
        FALLOS_OUTPUT = data["fallos_output"]
        
        RIESGO_F = FALLOS_OUTPUT["riesgo"].lower()
        CONFIANZA_F = FALLOS_OUTPUT["confianza"]
        ESPESOR_F = FALLOS_OUTPUT["espesor"]
        
        RULE_NAME = f"inferencia-api-V{RIESGO_F}-{str(ESPESOR_F).replace('.', '_')}"

        # Creaci贸n del PROMPT DINMICO
        EVAL_TANQUE_CALL = f"(evaluar-tanque {EVAL_INPUT[0]} {EVAL_INPUT[1]} {EVAL_INPUT[2]} {EVAL_INPUT[3]} {EVAL_INPUT[4]} {EVAL_INPUT[5]} {EVAL_INPUT[6]} \"{EVAL_INPUT[7]}\" \"{EVAL_INPUT[8]}\" \"{EVAL_INPUT[9]}\" \"{EVAL_INPUT[10]}\" {EVAL_INPUT[11]})"

        PROMPT_LISA = textwrap.dedent(f"""
            Genera la 'defrule' LISA para cubrir un VACO DE CONOCIMIENTO.

            CONTEXTO DE EVALUACIN COMPLETO (INPUTS REALES):
            {EVAL_TANQUE_CALL}
            
            HECHOS SIN COBERTURA (OUTPUT de los modelos que fallan):
            - Nombre de la Regla: {RULE_NAME}
            - Hechos de Entrada: {{'riesgo': '{RIESGO_F}', 'confianza': {CONFIANZA_F}, 'espesor': {ESPESOR_F}}}

            TAREA CRTICA (INFERENCIA):
            Analiza este CONTEXTO COMPLETO. 
            1. DETERMINA la acci贸n y la norma.
            2. CODIFICA la conclusi贸n usando NICAMENTE (format t "Tu Acci贸n (Tu Norma).~%").
            3. El patr贸n de hecho DEBE ser (tank-risk (riesgo ?r) (confianza ?c) (espesor ?e)).
        """)

        # LLAMADA AL MODELO GEMINI
        config = types.GenerateContentConfig(
            system_instruction=SYSTEM_INSTRUCTION,
        )

        response = CLIENT.models.generate_content(
            model='gemini-2.5-pro',
            contents=PROMPT_LISA,
            config=config
        )
        
        regla_limpia = response.text.strip().replace("```lisp\n", "").replace("\n```", "")
        
        return {
            "status": "success",
            "rule_name": RULE_NAME,
            "lisa_rule": regla_limpia
        }

    except Exception as e:
        # Devolver un error JSON claro si falla la llamada o el parsing
        return {"status": "error", "message": f"Fallo en la inferencia LLM o API: {str(e)}"}

# ====================================================================
# 4. SERVIDOR SOCKET (COPIA DE LA ESTRUCTURA DE TU MODELO DE RIESGO)
# ====================================================================

def start_server(host=HOST, port=PORT):
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        # Reutilizar el socket para evitar errores despu茅s de un cierre abrupto
        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        s.bind((host, port))
        s.listen()
        print(f" Servidor de Inferencias LLM activo en {host}:{port}")
        
        while True:
            conn, addr = s.accept()
            with conn:
                print(f"Conexi贸n de inferencia desde {addr}")
                data_received = conn.recv(4096).decode() # Aumentado a 4KB para asegurar que el JSON completo entre

                result = {}
                try:
                    # El cliente debe enviar el JSON completo, incluyendo eval_input y fallos_output
                    parsed_data = json.loads(data_received)
                    result = generate_lisa_rule(parsed_data)
                except json.JSONDecodeError:
                    result = {"status": "error", "message": "JSON inv谩lido recibido."}
                except Exception as e:
                    result = {"status": "error", "message": f"Error al procesar la data: {str(e)}"}

                # Enviar el resultado serializado de vuelta al cliente (a帽adiendo salto de l铆nea)
                conn.sendall((json.dumps(result) + "\n").encode())

if __name__ == "__main__":
    start_server()
