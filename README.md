Sistema Experto H√≠brido: Evaluaci√≥n de Integridad de Tanques (Tank-Integrity AI)
üéØ Descripci√≥n del Proyecto
Tank-Integrity AI es un Sistema Experto H√≠brido dise√±ado para la toma de decisiones en tiempo real sobre la integridad mec√°nica de tanques de almacenamiento y recipientes a presi√≥n en la industria de hidrocarburos y qu√≠mica. Este sistema combina la precisi√≥n de modelos de Machine Learning (ML) con la auditabilidad y rigurosidad de la l√≥gica basada en reglas (Sistemas Expertos/IA Simb√≥lica), implementando un mecanismo de "Rule Gap" (Vac√≠o de Conocimiento) que garantiza la cobertura total de casos.

El Problema que Resuelve
Los sistemas de inspecci√≥n tradicionales a menudo fallan en escenarios de baja confianza o datos contradictorios (casos de borde), donde la recomendaci√≥n debe ir m√°s all√° de las normas est√°ndar (API 653, API 510). Este proyecto asegura que cada caso de incertidumbre detectado por los modelos de ML sea resuelto mediante la generaci√≥n din√°mica de conocimiento utilizando un Large Language Model (LLM) como componente de inferencia de respaldo.

üèóÔ∏è Arquitectura Neurosimb√≥lica
El proyecto est√° dise√±ado bajo una arquitectura de "cerebro dual" que orquesta tres componentes principales a trav√©s de Common Lisp/LISA:

1. N√∫cleo Simb√≥lico (Motor de Reglas LISA)
Tecnolog√≠a: Common Lisp (CL) utilizando el shell de sistemas expertos LISA.

Funci√≥n: Almacena y ejecuta las reglas de decisi√≥n de ingenier√≠a basadas en normas (API 653/510, ASME). Es el componente de auditor√≠a y decisi√≥n primaria.

2. Componentes Neuro (Modelos de Machine Learning)
Tecnolog√≠a: Servidores Microservice (Python/Flask) que exponen endpoints (Puertos 5000, 5001).

Funci√≥n: Proporcionan hechos de entrada al sistema (LISA):

Modelo de Riesgo (Risk Model): Predice la categor√≠a de riesgo ("alto", "medio", "bajo") y, crucialmente, la Confianza (?c) de esa predicci√≥n.

Modelo de Corrosi√≥n (Corrosion Model): Predice la agresividad de la corrosi√≥n.

3. Mecanismo de Inferencia H√≠brida (El LLM)
Tecnolog√≠a: Servidor Microservice que aloja un Large Language Model (LLM) configurado con ingenier√≠a de prompts.

Funci√≥n: Es el mecanismo de fallback. Solo se activa si el motor LISA no puede asertar un CONCLUSION-FOUND debido a que la confianza de los modelos de ML es demasiado baja (el Rule Gap). El LLM genera y devuelve una nueva regla LISA, cerrando el vac√≠o.

‚öôÔ∏è Caracter√≠sticas T√©cnicas y Funcionalidad
Flujo Operacional (Inferencia H√≠brida)
Activaci√≥n: El frontend (LISA) recibe los inputs del tanque (evaluar-tanque ...).

Consulta ML: LISA consulta los Modelos de ML para obtener los hechos TANK-RISK y CORROSION-FACT.

Evaluaci√≥n Simb√≥lica: LISA ejecuta sus reglas de ingenier√≠a (?c>0.6).

Detecci√≥n de Vac√≠o (Rule Gap):

Si Confianza ML >0.6: Una regla est√°ndar se dispara, aserta CONCLUSION-FOUND y se finaliza.

Si Confianza ML ‚â§0.6 (Duda): El motor detecta la falta del hecho CONCLUSION-FOUND y suspende la ejecuci√≥n.

Generaci√≥n de Conocimiento: Se llama al LLM con los hechos y inputs del tanque. El LLM infiere una soluci√≥n (acci√≥n + norma) y genera una nueva defrule LISA.

Actualizaci√≥n: La nueva regla se integra en la base de conocimientos, resolviendo permanentemente el punto ciego para futuras consultas.

Reglas Clave Generadas (Ejemplos de Vac√≠os Encontrados)
El sistema ha demostrado capacidad para generar reglas para escenarios complejos y de baja confianza, como:

API-580-BAJA-CONF: Riesgo Bajo, pero Confianza extremadamente baja (?c<0.4), requiriendo validaci√≥n de datos (API 580).

API-510-ALTO-RIESGO-BAJA-CONF: Riesgo Alto, pero Confianza dudosa (?c=0.52), requiriendo re-inspecci√≥n inmediata y recalcular el riesgo (API 510/580).

API-581-SCC-ALTO: Alto Riesgo por Condici√≥n Metal√∫rgica (Cloruros/Temperatura), requiriendo t√©cnicas avanzadas de NDT para agrietamiento (API 581).

üõ†Ô∏è Tecnolog√≠as Utilizadas
Motor de Reglas: LISA (Lisp-based Intelligent Software Agent)

Lenguaje Principal: Common Lisp

Microservicios ML/LLM: Python / Flask

Est√°ndares de Ingenier√≠a: API 653, API 510, API 580, ASME B31.3.

üöÄ Pr√≥ximos Pasos (Hoja de Ruta)
Integraci√≥n Final: Implementar las correcciones del prompt y las reglas generadas en la base de conocimientos de producci√≥n.

Pruebas de Cierre: Realizar pruebas de regresi√≥n para asegurar que las reglas reci√©n generadas no disparen falsos negativos o positivos.

Monitoreo del LLM: Implementar un registro detallado de las reglas generadas por el LLM para auditor√≠a continua y refinamiento del prompt.
